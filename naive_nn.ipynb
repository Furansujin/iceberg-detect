{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join('input', 'train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "def flat_band_radar_tensors(df_itertup):\n",
    "    b1 = np.array(df_itertup.band_1)\n",
    "    b2 = np.array(df_itertup.band_2)\n",
    "    b3 = (b1 + b2) / 2\n",
    "    flat_img = np.stack([scale(x) for x in (b1, b2, b3)], axis=-1).flatten()\n",
    "    return np.expand_dims(flat_img, axis=0).astype('float32', copy=False)\n",
    "\n",
    "\n",
    "def prepare_4d_tensors_flat(df):\n",
    "    return np.vstack(flat_band_radar_tensors(row) for row in df.itertuples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------TRAIN--------\n",
      "1103 tensors\n",
      "51.13% icebergs\n",
      "\n",
      "-----VALIDATION-----\n",
      "368 tensors\n",
      "51.36% icebergs\n"
     ]
    }
   ],
   "source": [
    "# we drop the missing incidence angles for the base model NN\n",
    "df_missing = df[df.inc_angle != 'na']\n",
    "\n",
    "train_df, valid_df = train_test_split(df_missing, random_state=42, test_size=.25)\n",
    "\n",
    "print('TRAIN'.center(20, '-'))\n",
    "train_tensors = prepare_4d_tensors_flat(train_df)\n",
    "train_targets = train_df.is_iceberg.values\n",
    "assert len(train_tensors) == len(train_targets)\n",
    "print(len(train_tensors), 'tensors')\n",
    "print('{:.2f}% icebergs\\n'.format((train_targets == 1).sum() / len(train_targets) * 100))\n",
    "\n",
    "print('VALIDATION'.center(20, '-'))\n",
    "valid_tensors = prepare_4d_tensors_flat(valid_df)\n",
    "valid_targets = valid_df.is_iceberg.values\n",
    "assert len(valid_tensors) == len(valid_targets)\n",
    "print(len(valid_tensors), 'tensors')\n",
    "print('{:.2f}% icebergs'.format((valid_targets == 1).sum() / len(valid_targets) * 100))\n",
    "\n",
    "assert valid_tensors.shape[1:] == train_tensors.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a fully connected neural network, aka a multi-layer perceptron, as a baseline model to compare our convolutional neural network's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 1024)              17281024  \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 17,806,337\n",
      "Trainable params: 17,806,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Sequential \n",
    "# from keras.layers import Dropout, BatchNormalization\n",
    "# from keras.models import Model, Sequential, Input\n",
    "\n",
    "dense_model = Sequential()\n",
    "\n",
    "dense_model.add(Dense(1024, activation='relu', input_shape=train_tensors.shape[1:]))\n",
    "dense_model.add(Dense(512, activation='relu'))\n",
    "dense_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "version = 3.1\n",
    "model_name = 'naive_nn_v{}'.format(version)\n",
    "weights_name = '{}.best.weights.hdf5'.format(model_name.replace('_', '.'))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
    "save_best = ModelCheckpoint(filepath=os.path.join('saved_models', weights_name), \n",
    "                            save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=3, min_lr=0.000000001, verbose=1)\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1103 samples, validate on 368 samples\n",
      "Epoch 1/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 0.9797 - acc: 0.6489\n",
      "Epoch 00001: val_loss improved from inf to 0.75344, saving model to saved_models\\naive.nn.v3.1.best.weights.hdf5\n",
      "1103/1103 [==============================] - 3s 2ms/step - loss: 0.9701 - acc: 0.6519 - val_loss: 0.7534 - val_acc: 0.7092\n",
      "Epoch 2/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9577\n",
      "Epoch 00002: val_loss improved from 0.75344 to 0.72213, saving model to saved_models\\naive.nn.v3.1.best.weights.hdf5\n",
      "1103/1103 [==============================] - 1s 912us/step - loss: 0.1340 - acc: 0.9583 - val_loss: 0.7221 - val_acc: 0.7283\n",
      "Epoch 3/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9908\n",
      "Epoch 00003: val_loss improved from 0.72213 to 0.64015, saving model to saved_models\\naive.nn.v3.1.best.weights.hdf5\n",
      "1103/1103 [==============================] - 1s 926us/step - loss: 0.0274 - acc: 0.9909 - val_loss: 0.6401 - val_acc: 0.7717\n",
      "Epoch 4/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9963\n",
      "Epoch 00004: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 728us/step - loss: 0.0074 - acc: 0.9964 - val_loss: 0.7159 - val_acc: 0.7663\n",
      "Epoch 5/100\n",
      "1056/1103 [===========================>..] - ETA: 0s - loss: 0.0094 - acc: 0.9991\n",
      "Epoch 00005: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 711us/step - loss: 0.0091 - acc: 0.9991 - val_loss: 0.6669 - val_acc: 0.7717\n",
      "Epoch 6/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9945\n",
      "Epoch 00006: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 713us/step - loss: 0.0244 - acc: 0.9946 - val_loss: 0.7031 - val_acc: 0.7690\n",
      "Epoch 7/100\n",
      "1056/1103 [===========================>..] - ETA: 0s - loss: 0.0061 - acc: 0.9991\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1103/1103 [==============================] - 1s 876us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.8120 - val_acc: 0.7745\n",
      "Epoch 8/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 00008: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 714us/step - loss: 0.0045 - acc: 0.9982 - val_loss: 0.7659 - val_acc: 0.7880\n",
      "Epoch 9/100\n",
      "1088/1103 [============================>.] - ETA: 0s - loss: 1.5018e-04 - acc: 1.0000\n",
      "Epoch 00009: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 728us/step - loss: 1.4892e-04 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.7880\n",
      "Epoch 10/100\n",
      "1056/1103 [===========================>..] - ETA: 0s - loss: 1.3551e-04 - acc: 1.0000\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1103/1103 [==============================] - 1s 749us/step - loss: 1.3370e-04 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.7853\n",
      "Epoch 11/100\n",
      "1024/1103 [==========================>...] - ETA: 0s - loss: 1.3033e-04 - acc: 1.0000\n",
      "Epoch 00011: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 726us/step - loss: 1.2894e-04 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.7853\n",
      "Epoch 12/100\n",
      "1024/1103 [==========================>...] - ETA: 0s - loss: 1.3240e-04 - acc: 1.0000\n",
      "Epoch 00012: val_loss did not improve\n",
      "1103/1103 [==============================] - 1s 726us/step - loss: 1.2839e-04 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.7853\n",
      "Epoch 13/100\n",
      "1056/1103 [===========================>..] - ETA: 0s - loss: 1.3047e-04 - acc: 1.0000\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "1103/1103 [==============================] - 1s 727us/step - loss: 1.2777e-04 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.7853\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "dense_model.fit(train_tensors, train_targets, epochs=epochs,\n",
    "                callbacks=[early_stop, save_best, reduce_lr], verbose=1,\n",
    "                validation_data=(valid_tensors, valid_targets));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.load_weights(os.path.join('saved_models', weights_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1471/1471 [==============================] - 0s 189us/step\n"
     ]
    }
   ],
   "source": [
    "train_eval = dense_model.evaluate(prepare_4d_tensors_flat(df_missing), df_missing.is_iceberg.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------metrics on all tensors---------\n",
      "binary_crossentropy      = 0.1657\n",
      "accuracy                 = 94.086%\n"
     ]
    }
   ],
   "source": [
    "print('metrics on all tensors'.center(40, '-'))\n",
    "print(dense_model.loss.ljust(len(dense_model.loss)+5), '=', round(train_eval[0], 6))\n",
    "print(dense_model.metrics[0].ljust(len(dense_model.loss)+5), '=', '{:2.3f}%'.format(train_eval[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(os.path.join('input', 'test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensors = prepare_4d_tensors_flat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dense_model.predict(test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e6a00c8b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "x_label = model_name + ' | iceberg probability'\n",
    "ax = sns.distplot(preds, axlabel=x_label, label='TEST', bins=50, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  is_iceberg\n",
      "0  5941774d    0.025396\n",
      "1  4023181e    0.998785\n",
      "2  b20200e4    0.999968\n",
      "3  e7f018bb    0.999410\n",
      "4  4371c8c3    0.999972\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': test_df.id, 'is_iceberg': preds.reshape(preds.shape[0])})\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join('output', '{}.csv'.format(model_name)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
